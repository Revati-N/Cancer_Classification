{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, LayerNormalization, MultiHeadAttention, Add\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------------\n",
    "# PARAMETERS (OPTIMIZED FOR MEMORY)\n",
    "# -------------------------------\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 16  # REDUCED from 32 to 16\n",
    "num_classes = 2\n",
    "epochs = 20\n",
    "\n",
    "# Optimized Multiscale Parameters - removed 4x4 patches\n",
    "patch_sizes = [16, 8]  # CHANGED: removed 4 to reduce memory\n",
    "depths = [2, 4]  # CHANGED: adjusted depths\n",
    "dims = [96, 192]  # CHANGED: adjusted dimensions\n",
    "num_heads_list = [3, 6]  # CHANGED: adjusted heads\n",
    "mlp_dims = [384, 768]  # CHANGED: adjusted MLP dims\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# -------------------------------\n",
    "# DEFINE DIRECTORIES FOR ALL CANCER TYPES\n",
    "# -------------------------------\n",
    "malignant_dirs = [\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\all_early\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\all_pre\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\all_pro\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\breast_malignant\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\colon_aca\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\lung_aca\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\lung_scc\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Malignant\\oral_scc\"\n",
    "]\n",
    "\n",
    "benign_dirs = [\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Benign\\all_benign\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Benign\\breast_benign\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Benign\\colon_bnt\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Benign\\lung_bnt\",\n",
    "    r\"E:\\LY Project\\Multi Cancer\\Data\\Benign\\oral_normal\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD DATA FROM MULTIPLE DIRECTORIES\n",
    "# -------------------------------\n",
    "print(\"Loading data from multiple directories...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def load_images_from_directories(directories, label):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for directory in directories:\n",
    "        if not os.path.exists(directory):\n",
    "            print(f\"âš  Warning: Directory not found - {directory}\")\n",
    "            continue\n",
    "        \n",
    "        files = [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'))]\n",
    "        \n",
    "        folder_name = os.path.basename(directory)\n",
    "        print(f\"  {folder_name}: {len(files)} images\")\n",
    "        \n",
    "        image_paths.extend(files)\n",
    "        labels.extend([label] * len(files))\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "print(\"\\nMALIGNANT Cancer Types:\")\n",
    "malignant_paths, malignant_labels = load_images_from_directories(malignant_dirs, label=1)\n",
    "\n",
    "print(\"\\nBENIGN Cancer Types:\")\n",
    "benign_paths, benign_labels = load_images_from_directories(benign_dirs, label=0)\n",
    "\n",
    "all_image_paths = malignant_paths + benign_paths\n",
    "all_labels = malignant_labels + benign_labels\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total images: {len(all_image_paths)}\")\n",
    "print(f\"  Malignant: {len(malignant_paths)} ({100*len(malignant_paths)/len(all_image_paths):.1f}%)\")\n",
    "print(f\"  Benign: {len(benign_paths)} ({100*len(benign_paths)/len(all_image_paths):.1f}%)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# CREATE TF.DATA.DATASET\n",
    "# -------------------------------\n",
    "def load_and_preprocess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image = image / 255.0\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "path_ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_labels))\n",
    "path_ds = path_ds.shuffle(buffer_size=len(all_image_paths), seed=42)\n",
    "\n",
    "train_size = int(0.8 * len(all_image_paths))\n",
    "val_size = len(all_image_paths) - train_size\n",
    "\n",
    "train_ds = path_ds.take(train_size)\n",
    "val_ds = path_ds.skip(train_size)\n",
    "\n",
    "print(f\"Training samples: {train_size}\")\n",
    "print(f\"Validation samples: {val_size}\")\n",
    "print(f\"Batch size: {batch_size}\\n\")\n",
    "\n",
    "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# -------------------------------\n",
    "# MULTISCALE VISION TRANSFORMER COMPONENTS\n",
    "# -------------------------------\n",
    "\n",
    "class PatchEmbedding(layers.Layer):\n",
    "    \"\"\"Extract patches and embed them\"\"\"\n",
    "    def __init__(self, patch_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.projection = Dense(embed_dim)\n",
    "    \n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            x,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        patch_dim = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "        patches = self.projection(patches)\n",
    "        return patches\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"Memory-efficient Transformer block\"\"\"\n",
    "    def __init__(self, dim, num_heads, mlp_dim, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.mlp_dim = mlp_dim\n",
    "        \n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=dim // num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        \n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp = keras.Sequential([\n",
    "            Dense(mlp_dim, activation='gelu'),\n",
    "            Dropout(dropout),\n",
    "            Dense(dim),\n",
    "            Dropout(dropout)\n",
    "        ])\n",
    "        self.add1 = Add()\n",
    "        self.add2 = Add()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_output = self.attention(x_norm, x_norm, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        x = self.add1([x, attn_output])\n",
    "        \n",
    "        x_norm = self.norm2(x)\n",
    "        mlp_output = self.mlp(x_norm, training=training)\n",
    "        x = self.add2([x, mlp_output])\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MultiScaleViT(keras.Model):\n",
    "    \"\"\"Memory-optimized Multiscale Vision Transformer\"\"\"\n",
    "    def __init__(self, patch_sizes, depths, dims, num_heads_list, mlp_dims, \n",
    "                 num_classes, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_sizes = patch_sizes\n",
    "        self.depths = depths\n",
    "        self.dims = dims\n",
    "        self.num_heads_list = num_heads_list\n",
    "        self.mlp_dims = mlp_dims\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Patch embeddings for each scale\n",
    "        self.patch_embeddings = [\n",
    "            PatchEmbedding(patch_sizes[i], dims[i], name=f\"patch_embed_{i}\")\n",
    "            for i in range(len(patch_sizes))\n",
    "        ]\n",
    "        \n",
    "        # Pre-compute positional embeddings\n",
    "        self.pos_embeddings = []\n",
    "        for i in range(len(patch_sizes)):\n",
    "            num_patches = ((img_height // patch_sizes[i]) ** 2)\n",
    "            pos_embed = self.add_weight(\n",
    "                name=f\"pos_embed_{i}\",\n",
    "                shape=(1, num_patches, dims[i]),\n",
    "                initializer=\"random_normal\",\n",
    "                trainable=True,\n",
    "                dtype=tf.float32\n",
    "            )\n",
    "            self.pos_embeddings.append(pos_embed)\n",
    "        \n",
    "        # Transformer blocks for each scale\n",
    "        self.transformer_blocks = []\n",
    "        for i in range(len(patch_sizes)):\n",
    "            blocks = [\n",
    "                TransformerBlock(dims[i], num_heads_list[i], mlp_dims[i], dropout)\n",
    "                for _ in range(depths[i])\n",
    "            ]\n",
    "            self.transformer_blocks.append(blocks)\n",
    "        \n",
    "        # Classification head\n",
    "        self.norm = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.fc1 = Dense(512, activation='gelu')\n",
    "        self.dropout2 = Dropout(0.3)\n",
    "        self.fc2 = Dense(256, activation='gelu')\n",
    "        self.classifier = Dense(num_classes, activation='softmax')\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        scale_features = []\n",
    "        \n",
    "        # Process at multiple scales\n",
    "        for scale_idx in range(len(self.patch_sizes)):\n",
    "            # Extract and embed patches\n",
    "            x_patches = self.patch_embeddings[scale_idx](x)\n",
    "            \n",
    "            # Add positional embeddings\n",
    "            x_patches = x_patches + self.pos_embeddings[scale_idx]\n",
    "            \n",
    "            # Apply transformer blocks\n",
    "            for block in self.transformer_blocks[scale_idx]:\n",
    "                x_patches = block(x_patches, training=training)\n",
    "            \n",
    "            # Global average pooling\n",
    "            scale_features.append(tf.reduce_mean(x_patches, axis=1))\n",
    "        \n",
    "        # Concatenate features from all scales\n",
    "        x = tf.concat(scale_features, axis=-1)\n",
    "        \n",
    "        # Classification head\n",
    "        x = self.norm(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# BUILD MULTISCALE VIT MODEL\n",
    "# -------------------------------\n",
    "print(\"Building Memory-Optimized Multiscale Vision Transformer...\")\n",
    "print(f\"Patch sizes: {patch_sizes}\")\n",
    "print(f\"Depths: {depths}\")\n",
    "print(f\"Dimensions: {dims}\")\n",
    "print(f\"Attention heads: {num_heads_list}\")\n",
    "print(f\"Number of patches per scale: {[(img_height//p)**2 for p in patch_sizes]}\\n\")\n",
    "\n",
    "model = MultiScaleViT(\n",
    "    patch_sizes=patch_sizes,\n",
    "    depths=depths,\n",
    "    dims=dims,\n",
    "    num_heads_list=num_heads_list,\n",
    "    mlp_dims=mlp_dims,\n",
    "    num_classes=num_classes,\n",
    "    dropout=dropout_rate\n",
    ")\n",
    "\n",
    "# Build model\n",
    "model.build(input_shape=(None, img_height, img_width, 3))\n",
    "print(\"\\nModel Architecture Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------\n",
    "# COMPILE MODEL\n",
    "# -------------------------------\n",
    "print(\"\\nCompiling model with AdamW optimizer...\")\n",
    "optimizer = AdamW(learning_rate=0.0005, weight_decay=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# CALLBACKS\n",
    "# -------------------------------\n",
    "checkpoint_filepath = 'best_mvit_cancer_model.weights.h5'\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath, \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# TRAIN MODEL\n",
    "# -------------------------------\n",
    "print(f\"\\nTraining for {epochs} epochs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed.\")\n",
    "print(f\"Best model saved at {checkpoint_filepath}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# -------------------------------\n",
    "# PLOT TRAINING HISTORY\n",
    "# -------------------------------\n",
    "print(\"\\nPlotting training history...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy', marker='o')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s')\n",
    "axes[0].set_title('Multiscale ViT - Model Accuracy', fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history.history['loss'], label='Training Loss', marker='o')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss', marker='s')\n",
    "axes[1].set_title('Multiscale ViT - Model Loss', fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mvit_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# EVALUATION\n",
    "# -------------------------------\n",
    "print(\"\\nLoading best model for evaluation...\")\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "print(\"\\nEvaluating model on validation set...\")\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nPredicting classes on validation data...\")\n",
    "\n",
    "y_pred_probs = []\n",
    "y_true = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_pred_probs.extend(predictions)\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "y_pred_probs = np.array(y_pred_probs)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "class_labels = ['Benign', 'Malignant']\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues', \n",
    "    xticklabels=class_labels, \n",
    "    yticklabels=class_labels,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - Multiscale ViT\\n(Benign vs Malignant)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mvit_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT - MULTISCALE VIT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels, digits=4))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "y_pred_probs_positive = y_pred_probs[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs_positive)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve - Multiscale ViT', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mvit_roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true, y_pred, average=None, labels=[0, 1]\n",
    ")\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED METRICS - MULTISCALE VIT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"Precision (Benign): {precision[0]:.4f}\")\n",
    "print(f\"Recall (Benign): {recall[0]:.4f}\")\n",
    "print(f\"F1-Score (Benign): {f1[0]:.4f}\")\n",
    "print(f\"Precision (Malignant): {precision[1]:.4f}\")\n",
    "print(f\"Recall (Malignant): {recall[1]:.4f}\")\n",
    "print(f\"F1-Score (Malignant): {f1[1]:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTISCALE VISION TRANSFORMER COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
