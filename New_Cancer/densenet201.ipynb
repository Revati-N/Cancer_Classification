{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca4668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# PARAMETERS\n",
    "train_dir = r\"E:\\LY Project\\Multi Cancer\\Data\"  # Folder with 2 subfolders (Benign and Malignant)\n",
    "img_height, img_width = 224, 224    # DenseNet201 input size\n",
    "batch_size = 32\n",
    "num_classes = 2  # Binary classification\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD DATA - NO AUGMENTATION, ONLY RESIZE AND RESCALE\n",
    "# -------------------------------\n",
    "print(\"Loading training data without augmentation (only rescaling)...\")\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # 20% validation split\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD DENSENET201 BASE MODEL AND FREEZE LAYERS\n",
    "# -------------------------------\n",
    "print(\"Loading DenseNet201 pre-trained base model...\")\n",
    "base_model = DenseNet201(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(img_height, img_width, 3)\n",
    ")\n",
    "\n",
    "\n",
    "# Freeze all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "print(f\"Frozen {len(base_model.layers)} layers of DenseNet201 base.\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CLASSIFIER ON TOP\n",
    "# -------------------------------\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # DenseNet201 uses GAP instead of Flatten\n",
    "x = Dense(512, activation='relu')(x)  # Larger dense layer for complex features\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Display model summary\n",
    "print(\"\\nModel Architecture Summary:\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# COMPILE MODEL\n",
    "# -------------------------------\n",
    "print(\"\\nCompiling model...\")\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# CALLBACKS\n",
    "# -------------------------------\n",
    "checkpoint_filepath = 'best_densenet201_cancer_model.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath, \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# TRAIN MODEL\n",
    "# -------------------------------\n",
    "print(f\"\\nTraining for {epochs} epochs...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nTraining completed.\")\n",
    "print(f\"Best model saved at {checkpoint_filepath}\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# PLOT TRAINING HISTORY\n",
    "# -------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD BEST MODEL FROM CHECKPOINT\n",
    "# -------------------------------\n",
    "print(\"\\nLoading best model for evaluation...\")\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# EVALUATE ON VALIDATION SET\n",
    "# -------------------------------\n",
    "print(\"\\nEvaluating model on validation set...\")\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# PREDICTIONS AND CONFUSION MATRIX\n",
    "# -------------------------------\n",
    "print(\"\\nPredicting classes on validation data...\")\n",
    "validation_generator.reset()  # Reset generator for consistent predictions\n",
    "val_steps = validation_generator.samples // validation_generator.batch_size + 1\n",
    "\n",
    "\n",
    "# Predict probabilities for validation data\n",
    "y_pred_probs = model.predict(validation_generator, steps=val_steps)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "\n",
    "# True labels\n",
    "y_true = validation_generator.classes[:len(y_pred)]  # Match predictions length\n",
    "\n",
    "\n",
    "# Labels for confusion matrix and classification report\n",
    "class_labels = list(validation_generator.class_indices.keys())\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Display confusion matrix as heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues', \n",
    "    xticklabels=class_labels, \n",
    "    yticklabels=class_labels,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - DenseNet201', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT - DENSENET201\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# ADDITIONAL METRICS\n",
    "# -------------------------------\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# For binary classification, extract probabilities for positive class\n",
    "y_pred_probs_positive = y_pred_probs[:len(y_true), 1]\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs_positive)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
